{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession, Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.wrapper import JavaEstimator, JavaModel\n",
    "from pyspark.ml.param.shared import HasFeaturesCol, HasLabelCol\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, VectorIndexer, Bucketizer\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "# from xgboost import XGBClassifier\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /Users/stirlingwaite/Projects/personal/utah-data-engineering-pyspark/jars/xgboost4j-spark-0.72.jar,/Users/stirlingwaite/Projects/personal/utah-data-engineering-pyspark/jars/xgboost4j-0.72.jar pyspark-shell'\n",
    "\n",
    "conf = SparkConf()\\\n",
    "                .setMaster(\"local[2]\")\\\n",
    "                .setAppName(\"xgbooster\")\\\n",
    "                .set(\"spark.executor.memory\", \"6g\")\\\n",
    "                .set(\"spark.driver.memory\", \"6g\") \n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "sc.addPyFile(\"/Users/stirlingwaite/Projects/personal/utah-data-engineering-pyspark/jars/sparkxgb.zip\")\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession.builder.appName(\"spark play\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gender_df = spark.read.csv(\"file:///Users/stirlingwaite/Projects/personal/utah-data-engineering-pyspark/data/gender_submission.csv\", header=True, mode=\"DROPMALFORMED\", inferSchema='true', encoding=\"utf-8\").persist()\n",
    "training_df = spark.read.csv(\"file:///Users/stirlingwaite/Projects/personal/utah-data-engineering-pyspark/data/train.csv\", header=True, mode=\"DROPMALFORMED\", inferSchema='true', encoding=\"utf-8\").persist()\n",
    "testing_df = spark.read.csv(\"file:///Users/stirlingwaite/Projects/personal/utah-data-engineering-pyspark/data/test.csv\", header=True, mode=\"DROPMALFORMED\", inferSchema='true', encoding=\"utf-8\").persist()\n",
    "\n",
    "training_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------------+---------+---+---+---+---+---+---+----+----+------------+---------+--------+--------+-----+------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|      Surname|Honorific|Mil|Doc|Rev|Nob| Mr|Mrs|Miss|Mstr|TotalFamSize|Singleton|SmallFam|LargeFam|Child|Mother|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------------+---------+---+---+---+---+---+---+----+----+------------+---------+--------+--------+-----+------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|       Braund|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           2|        0|       1|       0|    0|     0|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|      Cumings|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           2|        0|       1|       0|    0|     0|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|    Heikkinen|     Miss|  0|  0|  0|  0|  0|  0|   1|   0|           1|        1|       0|       0|    0|     0|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|     Futrelle|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           2|        0|       1|       0|    0|     0|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|        Allen|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|        Moran|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|     McCarthy|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|      Palsson|   Master|  0|  0|  0|  0|  0|  0|   0|   1|           5|        0|       0|       1|    1|     0|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|      Johnson|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           3|        0|       1|       0|    0|     1|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|       Nasser|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           2|        0|       1|       0|    1|     0|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|    Sandstrom|     Miss|  0|  0|  0|  0|  0|  0|   1|   0|           3|        0|       1|       0|    1|     0|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|      Bonnell|     Miss|  0|  0|  0|  0|  0|  0|   1|   0|           1|        1|       0|       0|    0|     0|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|  Saundercock|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|    Andersson|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           7|        0|       0|       1|    0|     0|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|      Vestrom|     Miss|  0|  0|  0|  0|  0|  0|   1|   0|           1|        1|       0|       0|    1|     0|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|      Hewlett|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|         Rice|   Master|  0|  0|  0|  0|  0|  0|   0|   1|           6|        0|       0|       1|    1|     0|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|     Williams|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|Vander Planke|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           2|        0|       1|       0|    0|     0|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|   Masselmani|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------------+---------+---+---+---+---+---+---+----+----+------------+---------+--------+--------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# // Feature Engineering Step:\n",
    "# // Surname Regex: Pull last name from the Name record\n",
    "# // Honorific Regex: Pull title from the Name column.  Create a column per title.\n",
    "# // Family Size: Add the SibSp and Parch columns, and a 1 for self\n",
    "# // Family Buckets: Singleton = 1, SmallFam = 2 to 4, LargeFam > 5\n",
    "# // Child feature: Is the person 18 or under\n",
    "# // Mother feature: 16 or older, female, Honorific other than \"Miss\", and Parch greater than 0\n",
    "    \n",
    "training_features = (training_df\n",
    "                    .withColumn(\"Surname\", regexp_extract(col(\"Name\"),\"([\\\\w ']+),\",1))\n",
    "                    .withColumn(\"Honorific\", regexp_extract(col(\"Name\"),\"(.*?)([\\\\w]+?)[.]\",2))\n",
    "                    .withColumn(\"Mil\", when((col(\"Honorific\") == \"Col\") | (col(\"Honorific\") == \"Major\") | (col(\"Honorific\") == \"Capt\"), 1).otherwise(0))\n",
    "                    .withColumn(\"Doc\", when(col(\"Honorific\") == \"Dr\", 1).otherwise(0))\n",
    "                    .withColumn(\"Rev\", when(col(\"Honorific\") == \"Rev\", 1).otherwise(0))\n",
    "                    .withColumn(\"Nob\", when((col(\"Honorific\") == \"Sir\") |\n",
    "                        (col(\"Honorific\") == \"Countess\") |\n",
    "                        (col(\"Honorific\") == \"Count\") |\n",
    "                        (col(\"Honorific\") == \"Duke\") |\n",
    "                        (col(\"Honorific\") == \"Duchess\") |\n",
    "                        (col(\"Honorific\") == \"Jonkheer\") |\n",
    "                        (col(\"Honorific\") == \"Don\") |\n",
    "                        (col(\"Honorific\") == \"Dona\") |\n",
    "                        (col(\"Honorific\") == \"Lord\") |\n",
    "                        (col(\"Honorific\") == \"Lady\") |\n",
    "                        (col(\"Honorific\") == \"Earl\") |\n",
    "                        (col(\"Honorific\") == \"Baron\"), 1).otherwise(0))\n",
    "                    .withColumn(\"Mr\", when(col(\"Honorific\") == \"Mr\", 1).otherwise(0))\n",
    "                    .withColumn(\"Mrs\", when((col(\"Honorific\") == \"Mrs\") | (col(\"Honorific\") == \"Mme\"), 1).otherwise(0))\n",
    "                    .withColumn(\"Miss\", when((col(\"Honorific\") == \"Miss\") | (col(\"Honorific\") == \"Mlle\"), 1).otherwise(0))\n",
    "                    .withColumn(\"Mstr\", when(col(\"Honorific\") == \"Master\", 1).otherwise(0))\n",
    "                    .withColumn(\"TotalFamSize\", col(\"SibSp\") + col(\"Parch\") + 1)\n",
    "                    .withColumn(\"Singleton\", when(col(\"TotalFamSize\") == 1, 1).otherwise(0))\n",
    "                    .withColumn(\"SmallFam\", when((col(\"TotalFamSize\") <= 4) & (col(\"TotalFamSize\") > 1), 1).otherwise(0))\n",
    "                    .withColumn(\"LargeFam\", when(col(\"TotalFamSize\") >= 5, 1).otherwise(0))\n",
    "                    .withColumn(\"Child\", when((col(\"Age\") <= 18), 1).otherwise(0))\n",
    "                    .withColumn(\"Mother\", when((col(\"Age\") > 15) &\n",
    "                        (col(\"Parch\") > 0) & \n",
    "                        (col(\"Miss\") == 0) & \n",
    "                        (col(\"Sex\") == \"female\"),1).otherwise(0)))\n",
    "training_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+------------------+---------+---------+------------------+\n",
      "|Pclass|Embarked|count|         avg(Fare)|min(Fare)|max(Fare)| stddev_samp(Fare)|\n",
      "+------+--------+-----+------------------+---------+---------+------------------+\n",
      "|     1|    null|    2|              80.0|     80.0|     80.0|               0.0|\n",
      "|     1|       C|   85|104.71852941176469|    26.55| 512.3292|  99.0939349696501|\n",
      "|     1|       Q|    2|              90.0|     90.0|     90.0|               0.0|\n",
      "|     1|       S|  127| 70.36486220472443|      0.0|    263.0|58.811277761795566|\n",
      "|     2|       C|   17|25.358335294117644|     12.0|  41.5792|11.345067090697457|\n",
      "|     2|       Q|    3|             12.35|    12.35|    12.35|               0.0|\n",
      "|     2|       S|  164|20.327439024390245|      0.0|     73.5|13.630741099088103|\n",
      "|     3|       C|   66|11.214083333333337|   4.0125|  22.3583| 4.871528353625736|\n",
      "|     3|       Q|   72|11.183393055555557|     6.75|   29.125| 6.721676511682005|\n",
      "|     3|       S|  353| 14.64408300283288|      0.0|    69.55|13.276608721649458|\n",
      "+------+--------+-----+------------------+---------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# // Explore the data\n",
    "(training_features.groupBy(\"Pclass\",\"Embarked\")\n",
    "                  .agg(\n",
    "                      count(\"*\").alias(\"count\"),\n",
    "                      avg(\"Fare\"),\n",
    "                      min(\"Fare\"),\n",
    "                      max(\"Fare\"),\n",
    "                      stddev(\"Fare\")\n",
    "                  )\n",
    "                  .orderBy(\"Pclass\",\"Embarked\")\n",
    "                  .show())\n",
    "\n",
    "training_features.createOrReplaceTempView(\"training_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------+\n",
      "|Pclass|Embarked|Median_Fare|\n",
      "+------+--------+-----------+\n",
      "|     1|    null|       80.0|\n",
      "|     1|       Q|       90.0|\n",
      "|     1|       C|    78.2667|\n",
      "|     1|       S|       52.0|\n",
      "+------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          SELECT \n",
    "              Pclass,\n",
    "              Embarked,\n",
    "              percentile_approx(Fare, 0.5) AS Median_Fare \n",
    "          FROM training_features \n",
    "          WHERE Fare IS NOT NULL \n",
    "          AND Pclass = 1 \n",
    "          GROUP BY Pclass, Embarked\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------------+---------+---+---+---+---+---+---+----+----+------------+---------+--------+--------+-----+------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|      Surname|Honorific|Mil|Doc|Rev|Nob| Mr|Mrs|Miss|Mstr|TotalFamSize|Singleton|SmallFam|LargeFam|Child|Mother|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------------+---------+---+---+---+---+---+---+----+----+------------+---------+--------+--------+-----+------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|       Braund|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           2|        0|       1|       0|    0|     0|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|      Cumings|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           2|        0|       1|       0|    0|     0|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|    Heikkinen|     Miss|  0|  0|  0|  0|  0|  0|   1|   0|           1|        1|       0|       0|    0|     0|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|     Futrelle|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           2|        0|       1|       0|    0|     0|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|        Allen|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|        Moran|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|     McCarthy|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|      Palsson|   Master|  0|  0|  0|  0|  0|  0|   0|   1|           5|        0|       0|       1|    1|     0|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|      Johnson|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           3|        0|       1|       0|    0|     1|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|       Nasser|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           2|        0|       1|       0|    1|     0|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|    Sandstrom|     Miss|  0|  0|  0|  0|  0|  0|   1|   0|           3|        0|       1|       0|    1|     0|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|      Bonnell|     Miss|  0|  0|  0|  0|  0|  0|   1|   0|           1|        1|       0|       0|    0|     0|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|  Saundercock|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|    Andersson|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           7|        0|       0|       1|    0|     0|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|      Vestrom|     Miss|  0|  0|  0|  0|  0|  0|   1|   0|           1|        1|       0|       0|    1|     0|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|      Hewlett|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|         Rice|   Master|  0|  0|  0|  0|  0|  0|   0|   1|           6|        0|       0|       1|    1|     0|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|     Williams|       Mr|  0|  0|  0|  0|  1|  0|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|Vander Planke|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           2|        0|       1|       0|    0|     0|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|   Masselmani|      Mrs|  0|  0|  0|  0|  0|  1|   0|   0|           1|        1|       0|       0|    0|     0|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------------+---------+---+---+---+---+---+---+----+----+------------+---------+--------+--------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# // Impute Embarked column\n",
    "# // From the discovery above, the likely port is C, since the Median for C is closest to 80.\n",
    "train_embarked = training_features.na.fill(\"C\", [\"Embarked\"])\n",
    "print(train_embarked.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|Honorific|nullAge|\n",
      "+---------+-------+\n",
      "|     Miss|     36|\n",
      "|   Master|      4|\n",
      "|       Mr|    119|\n",
      "|       Dr|      1|\n",
      "|      Mrs|     17|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# // Perform discovery on missing data in Age column\n",
    "# // Create the temp table view so we can perform spark.sql queries on the dataframe\n",
    "train_embarked.createOrReplaceTempView(\"train_embarked\")\n",
    "\n",
    "# // Explore the data\n",
    "# // Count nulls for each Honorific.  Some titles can imply age (miss,master,etc)\n",
    "spark.sql(\"SELECT Honorific,count(*) as nullAge FROM train_embarked WHERE Age IS NULL GROUP BY Honorific\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|Honorific|avgAge|\n",
      "+---------+------+\n",
      "|     Miss|  22.0|\n",
      "|   Master|   5.0|\n",
      "|       Mr|  32.0|\n",
      "|       Dr|  42.0|\n",
      "|      Mrs|  36.0|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# // Calculate the average age for the Honorific titles that have nulls\n",
    "spark.sql(\"SELECT Honorific,round(avg(Age)) as avgAge FROM train_embarked WHERE Age IS NOT NULL AND Honorific IN ('Miss','Master','Mr','Dr','Mrs') GROUP BY Honorific\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Impute the missing Age values for the relevant Honorific columns and union the data back together\n",
    "train_miss_df = train_embarked.na.fill(22.0).where(\"Honorific = 'Miss'\")\n",
    "train_master_df = train_embarked.na.fill(5.0).where(\"Honorific = 'Master'\")\n",
    "train_mr_df = train_embarked.na.fill(32.0).where(\"Honorific = 'Mr'\")\n",
    "train_dr_df = train_embarked.na.fill(42.0).where(\"Honorific = 'Dr'\")\n",
    "train_mrs_df = train_embarked.na.fill(36.0).where(\"Honorific = 'Mrs'\")\n",
    "train_remainder_df = spark.sql(\"SELECT * FROM train_embarked WHERE Honorific NOT IN ('Miss','Master','Dr','Mr','Mrs')\")\n",
    "train_combined_df = train_remainder_df.union(train_miss_df).union(train_master_df).union(train_mr_df).union(train_dr_df).union(train_mrs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Convert the categorical (string) values into numeric values\n",
    "# // Convert the categorical (string) values into numeric values\n",
    "gender_indexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\").setHandleInvalid(\"keep\")\n",
    "embark_indexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkIndex\").setHandleInvalid(\"keep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Convert the numerical index columns into One Hot columns\n",
    "# // The One Hot columns are binary {0,1} values of the categories\n",
    "gender_encoder = OneHotEncoder(dropLast=False, inputCol=\"SexIndex\", outputCol=\"SexVec\")\n",
    "embark_encoder = OneHotEncoder(dropLast=False, inputCol=\"EmbarkIndex\", outputCol=\"EmbarkVec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Create 8 buckets for the fares, turning a continuous feature into a discrete range# // Cre \n",
    "fare_splits = [0.0,10.0,20.0,30.0,40.0,60.0,120.0, float(\"+inf\")]\n",
    "fare_bucketize = Bucketizer().setInputCol(\"Fare\").setOutputCol(\"FareBucketed\").setSplits(fare_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Create a vector of the features.  \n",
    "assembler = VectorAssembler().setInputCols([\"Pclass\", \"SexVec\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"FareBucketed\", \"EmbarkVec\", \"Mil\", \"Doc\", \"Rev\", \"Nob\", \"Mr\", \"Mrs\", \"Miss\", \"Mstr\", \"TotalFamSize\", \"Singleton\", \"SmallFam\", \"LargeFam\", \"Child\", \"Mother\"]).setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Create the features pipeline and data frame\n",
    "# // The order is important here, Indexers have to come before the encoders\n",
    "training_features_pipeline = (Pipeline().setStages([gender_indexer, embark_indexer, gender_encoder, embark_encoder, fare_bucketize, assembler]))\n",
    "training_features_df = training_features_pipeline.fit(train_combined_df).transform(train_combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+----+----+-----+-----+--------+-------+-----+--------+---------+---------+---+---+---+---+---+---+----+----+------------+---------+--------+--------+-----+------+--------+-----------+-------------+-------------+------------+--------------------+\n",
      "|PassengerId|Survived|Pclass|                Name| Sex| Age|SibSp|Parch|  Ticket|   Fare|Cabin|Embarked|  Surname|Honorific|Mil|Doc|Rev|Nob| Mr|Mrs|Miss|Mstr|TotalFamSize|Singleton|SmallFam|LargeFam|Child|Mother|SexIndex|EmbarkIndex|       SexVec|    EmbarkVec|FareBucketed|            features|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+--------+-------+-----+--------+---------+---------+---+---+---+---+---+---+----+----+------------+---------+--------+--------+-----+------+--------+-----------+-------------+-------------+------------+--------------------+\n",
      "|         31|       0|     1|Uruchurtu, Don. M...|male|40.0|    0|    0|PC 17601|27.7208| null|       C|Uruchurtu|      Don|  0|  0|  0|  1|  0|  0|   0|   0|           1|        1|       0|       0|    0|     0|     0.0|        1.0|(3,[0],[1.0])|(4,[1],[1.0])|         2.0|(27,[0,1,4,7,8,10...|\n",
      "|        150|       0|     2|Byles, Rev. Thoma...|male|42.0|    0|    0|  244310|   13.0| null|       S|    Byles|      Rev|  0|  0|  1|  0|  0|  0|   0|   0|           1|        1|       0|       0|    0|     0|     0.0|        0.0|(3,[0],[1.0])|(4,[0],[1.0])|         1.0|(27,[0,1,4,7,8,9,...|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+--------+-------+-----+--------+---------+---------+---+---+---+---+---+---+----+----+------------+---------+--------+--------+-----+------+--------+-----------+-------------+-------------+------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# // Now that the data has been prepared, let's split the dataset into a training and test dataframe\n",
    "train_df, test_df = training_features_df.randomSplit([0.8, 0.2], seed = 12345)\n",
    "train_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineers Job Is Done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scientist Job Starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Survivors using XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostEstimator(JavaEstimator, HasFeaturesCol, HasLabelCol):\n",
    "    def __init__(self, xgb_param_map={}):\n",
    "        super(XGBoostEstimator, self).__init__()\n",
    "        sc = SparkContext._active_spark_context\n",
    "        scala_map = sc._jvm.PythonUtils.toScalaMap(xgb_param_map)\n",
    "        self._defaultParamMap = xgb_param_map\n",
    "        self._paramMap = xgb_param_map\n",
    "        self._from_XGBParamMap_to_params()\n",
    "        self._java_obj = self._new_java_obj(\n",
    "            \"ml.dmlc.xgboost4j.scala.spark.XGBoostEstimator\", self.uid, scala_map)\n",
    "\n",
    "    def _create_model(self, java_model):\n",
    "        return JavaModel(java_model)\n",
    "\n",
    "    def _from_XGBParamMap_to_params(self):\n",
    "        for param, value in self._paramMap.items():\n",
    "            setattr(self, param, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"max_depth\"] = 8\n",
    "params[\"gamma\"] = 0.0\n",
    "params[\"colsample_bylevel\"] = 1\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params[\"num_class\"] = 2\n",
    "params[\"booster\"] = \"gbtree\"\n",
    "params[\"num_rounds\"] = 20\n",
    "params[\"nWorkers\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Create an XGBoost Classifier\n",
    "xgbEstimator = XGBoostEstimator(params)\\\n",
    "                            .setFeaturesCol(\"features\")\\\n",
    "                            .setLabelCol(\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // XGBoost paramater grid\n",
    "xgbParamGrid = ParamGridBuilder() \\\n",
    "        .addGrid(xgbEstimator.max_depth, [16]) \\\n",
    "        .addGrid(xgbEstimator.eta, [0.015]) \\\n",
    "        .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Create the XGBoost pipeline\n",
    "pipeline = Pipeline().setStages([xgbEstimator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Setup the binary classifier evaluator\n",
    "evaluator = BinaryClassificationEvaluator().setLabelCol(\"Survived\")\\\n",
    "                                              .setRawPredictionCol(\"prediction\")\\\n",
    "                                              .setMetricName(\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator().setEstimator(pipeline) \\\n",
    "                      .setEvaluator(evaluator)\\\n",
    "                      .setEstimatorParamMaps(xgbParamGrid) \\\n",
    "                      .setNumFolds(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = xgb_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+-----+-----+--------+---+--------+----------+--------------------+\n",
      "|PID|Pclass|   Sex| Age|SibSp|Parch|     Hon|Fam|Survived|prediction|       probabilities|\n",
      "+---+------+------+----+-----+-----+--------+---+--------+----------+--------------------+\n",
      "|537|     1|  male|45.0|    0|    0|   Major|  1|       0|       1.0|[0.45705056190490...|\n",
      "|823|     1|  male|38.0|    0|    0|Jonkheer|  1|       0|       1.0|[0.45705056190490...|\n",
      "| 69|     3|female|17.0|    4|    2|    Miss|  7|       1|       0.0|[0.53711110353469...|\n",
      "|193|     3|female|19.0|    1|    0|    Miss|  2|       1|       0.0|           [0.5,0.5]|\n",
      "|217|     3|female|27.0|    0|    0|    Miss|  1|       1|       0.0|           [0.5,0.5]|\n",
      "|358|     2|female|38.0|    0|    0|    Miss|  1|       0|       1.0|[0.45705056190490...|\n",
      "|594|     3|female|22.0|    0|    2|    Miss|  3|       0|       1.0|[0.47225075960159...|\n",
      "|655|     3|female|18.0|    0|    0|    Miss|  1|       0|       1.0|[0.47225075960159...|\n",
      "|692|     3|female| 4.0|    0|    1|    Miss|  2|       1|       0.0|[0.51249736547470...|\n",
      "|170|     3|  male|28.0|    0|    0|      Mr|  1|       0|       1.0|[0.48750263452529...|\n",
      "|188|     1|  male|45.0|    0|    0|      Mr|  1|       1|       0.0|[0.50999867916107...|\n",
      "|391|     1|  male|36.0|    1|    2|      Mr|  4|       1|       0.0|           [0.5,0.5]|\n",
      "|570|     3|  male|32.0|    0|    0|      Mr|  1|       1|       0.0|[0.53857350349426...|\n",
      "|584|     1|  male|36.0|    0|    0|      Mr|  1|       0|       1.0|[0.47003597021102...|\n",
      "|623|     3|  male|20.0|    1|    1|      Mr|  3|       1|       0.0|[0.53857350349426...|\n",
      "|631|     1|  male|80.0|    0|    0|      Mr|  1|       1|       0.0|[0.53881067037582...|\n",
      "|646|     1|  male|48.0|    1|    0|      Mr|  2|       1|       0.0|           [0.5,0.5]|\n",
      "|749|     1|  male|19.0|    1|    0|      Mr|  2|       0|       1.0|[0.47502082586288...|\n",
      "|763|     3|  male|20.0|    0|    0|      Mr|  1|       1|       0.0|[0.53857350349426...|\n",
      "|805|     3|  male|27.0|    0|    0|      Mr|  1|       1|       0.0|[0.53857350349426...|\n",
      "|840|     1|  male|32.0|    0|    0|      Mr|  1|       1|       0.0|[0.51666051149368...|\n",
      "|873|     1|  male|33.0|    0|    0|      Mr|  1|       0|       1.0|[0.47003597021102...|\n",
      "|318|     2|  male|54.0|    0|    0|      Dr|  1|       0|       1.0|[0.49444466829299...|\n",
      "|399|     2|  male|23.0|    0|    0|      Dr|  1|       0|       1.0|[0.49444466829299...|\n",
      "| 50|     3|female|18.0|    1|    0|     Mrs|  2|       0|       1.0|[0.46505707502365...|\n",
      "|798|     3|female|31.0|    0|    0|     Mrs|  1|       1|       0.0|[0.52331638336181...|\n",
      "+---+------+------+----+-----+-----+--------+---+--------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.createOrReplaceTempView(\"results\")\n",
    "spark.sql(\"SELECT PassengerID as PID,Pclass,Sex,Age,SibSp,Parch,Honorific as Hon,TotalFamSize as Fam,Survived,prediction,probabilities FROM results where Survived != cast(prediction as int)\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8365709459459459"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# // What was the overall accuracy of the model, using AUC\n",
    "evaluator.evaluate(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
